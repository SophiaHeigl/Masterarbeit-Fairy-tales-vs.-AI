{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e0b68c00-e648-42b0-b192-75cf9e743681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, re\n",
    "from collections import Counter, defaultdict\n",
    "from pathlib import Path\n",
    "from typing import Dict, Iterable, List, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a287c7c5-4388-4a53-8b0b-02e26e4e6f41",
   "metadata": {},
   "source": [
    "1. Loading Corpus and large spacy model for lemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d2e77e0-a765-4043-80a9-ff735b3f2bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Lade spaCy Modell: de_core_news_lg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sophia\\anaconda3\\envs\\Working\\lib\\site-packages\\spacy\\util.py:910: UserWarning: [W095] Model 'de_core_news_lg' (3.8.0) was trained with spaCy v3.8.0 and may not be 100% compatible with the current version (3.7.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "CORPORA = {\n",
    "    \"Folk Fairy Tales\": r\"C:\\Users\\Sophia\\Downloads\\MA\\CORPORA\\German FFT\",\n",
    "    \"GPT-5\":            r\"C:\\Users\\Sophia\\Downloads\\MA\\CORPORA\\GPT-5\",\n",
    "    \"GPT-4o\":           r\"C:\\Users\\Sophia\\Downloads\\MA\\CORPORA\\GPT-4o\",\n",
    "}\n",
    "\n",
    "OUTDIR = r\"C:\\Users\\Sophia\\Downloads\\MA\\TABLES\\POS\"\n",
    "\n",
    "REPORT_POS = [\"NOUN\", \"PROPN\", \"VERB\", \"ADJ\", \"ADV\", \"PRON\", \"ADP\", \"AUX\", \"CCONJ\", \"SCONJ\"]\n",
    "\n",
    "EXCLUDE_STOPWORDS = False\n",
    "LOWERCASE_LEMMAS  = True    \n",
    "MIN_LEMMA_LEN     = 2 \n",
    "TOP_N_ADJ         = 10\n",
    "SPACY_MODEL = \"de_core_news_lg\" #large german model for this POS-tagging\n",
    "\n",
    "print(f\"[INFO] Lade spaCy Modell: {SPACY_MODEL}\")\n",
    "nlp = spacy.load(SPACY_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "967a0f9c-d0d9-44d5-850c-59f783e30fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Folk Fairy Tales]: 100%|██████████| 122/122 [00:20<00:00,  5.86it/s]\n",
      "[GPT-5]: 100%|██████████| 100/100 [00:13<00:00,  7.64it/s]\n",
      "[GPT-4o]: 100%|██████████| 100/100 [00:11<00:00,  8.34it/s]\n"
     ]
    }
   ],
   "source": [
    "def read_texts_from_dir(d: str) -> Iterable[str]:\n",
    "    for fp in glob.glob(str(Path(d) / \"**/*.txt\"), recursive=True):\n",
    "        try:\n",
    "            with open(fp, \"r\", encoding=\"utf-8\") as f:\n",
    "                yield f.read()\n",
    "        except Exception:\n",
    "            with open(fp, \"r\", encoding=\"latin-1\", errors=\"ignore\") as f:\n",
    "                yield f.read()\n",
    "\n",
    "def normalize_whitespace(s: str) -> str:\n",
    "    s = re.sub(r\"[ \\t\\f\\v]+\", \" \", s)\n",
    "    s = re.sub(r\"[ \\t\\f\\v]*\\n[ \\t\\f\\v]*\", \"\\n\", s)\n",
    "    return s\n",
    "\n",
    "def acceptable_token(tok) -> bool:\n",
    "    if tok.is_space or tok.is_punct:\n",
    "        return False\n",
    "    if tok.like_num:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def lemma_of(tok) -> str:\n",
    "    lem = tok.lemma_ if tok.lemma_ else tok.text\n",
    "    if LOWERCASE_LEMMAS:\n",
    "        lem = lem.lower()\n",
    "    lem = lem.replace(\"ß\", \"ss\")\n",
    "    return lem\n",
    "\n",
    "def analyze_corpus(name: str, dirpath: str) -> Dict[str, any]:\n",
    "    pos_counts = Counter()\n",
    "    total_tokens = 0\n",
    "    adj_counts = Counter()\n",
    "\n",
    "    texts = list(read_texts_from_dir(dirpath))\n",
    "    if not texts:\n",
    "        return {\"pos_counts\": pos_counts, \"total_tokens\": 0, \"adj_counts\": adj_counts}\n",
    "\n",
    "    for doc in tqdm(nlp.pipe((normalize_whitespace(t) for t in texts), batch_size=32),\n",
    "                    total=len(texts), desc=f\"[{name}]\"):\n",
    "        for tok in doc:\n",
    "            if not acceptable_token(tok):\n",
    "                continue\n",
    "            total_tokens += 1\n",
    "            pos = tok.pos_\n",
    "            pos_counts[pos] += 1\n",
    "\n",
    "            if pos == \"ADJ\":\n",
    "                lem = lemma_of(tok)\n",
    "                if len(lem) < MIN_LEMMA_LEN:\n",
    "                    continue\n",
    "                if EXCLUDE_STOPWORDS and tok.is_stop:\n",
    "                    continue\n",
    "                adj_counts[lem] += 1\n",
    "\n",
    "    return {\"pos_counts\": pos_counts, \"total_tokens\": total_tokens, \"adj_counts\": adj_counts}\n",
    "results = {}\n",
    "for cname, cdir in CORPORA.items():\n",
    "    results[cname] = analyze_corpus(cname, cdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dc3b8d-0d03-42fb-b4b2-a839180b8e6c",
   "metadata": {},
   "source": [
    "Build table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7513e17b-2807-466e-b31e-2af880b09d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Preview POS-share (Top 12) ===\n",
      "       Folk Fairy Tales     GPT-5    GPT-4o\n",
      "pos                                        \n",
      "NOUN           0.163053  0.181750  0.189505\n",
      "VERB           0.155519  0.157595  0.148746\n",
      "PRON           0.139417  0.128898  0.123340\n",
      "ADV            0.120775  0.104284  0.094316\n",
      "ADP            0.079172  0.081969  0.092983\n",
      "CCONJ          0.061995  0.065400  0.058178\n",
      "AUX            0.055431  0.048452  0.048170\n",
      "ADJ            0.034549  0.031575  0.036504\n",
      "SCONJ          0.026531  0.026477  0.023540\n",
      "PROPN          0.010048  0.020127  0.021979\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "for pos in REPORT_POS:\n",
    "    row = {\"pos\": pos}\n",
    "    for cname, res in results.items():\n",
    "        tot = res[\"total_tokens\"] or 1\n",
    "        share = res[\"pos_counts\"].get(pos, 0) / tot\n",
    "        row[cname] = round(share, 6)\n",
    "    rows.append(row)\n",
    "\n",
    "df_pos = pd.DataFrame(rows).set_index(\"pos\")\n",
    "df_pos[\"_mean\"] = df_pos.mean(axis=1)\n",
    "df_pos = df_pos.sort_values(\"_mean\", ascending=False).drop(columns=[\"_mean\"])\n",
    "\n",
    "pos_csv = Path(OUTDIR) / \"POS_shares_by_corpus.csv\"\n",
    "df_pos.to_csv(pos_csv, encoding=\"utf-8\")\n",
    "print(\"\\n=== Preview POS-share (Top 12) ===\")\n",
    "print(df_pos.head(12).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b4a427-2ad8-4894-b253-e1cfc68b702c",
   "metadata": {},
   "source": [
    "VISUALISATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e1f31e76-7a84-483f-b7f8-ba35345d6e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "df_pos_pct = (df_pos * 100).round(2)\n",
    "df_pos_pct.to_csv(Path(OUTDIR) / \"POS_shares_by_corpus_percent.csv\", encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "pos_order = list(df_pos_pct.index)\n",
    "corpora_order = list(CORPORA.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a4791612-6c31-4265-95a3-0d2d00c8775c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Visualisierungen gespeichert in: C:\\Users\\Sophia\\Downloads\\MA\\TABLES\\POS\n",
      " - POS_shares_grouped_bar.(png|pdf)\n",
      " - POS_shares_stacked100.(png|pdf)\n",
      " - POS_shares_heatmap.(png|pdf)\n"
     ]
    }
   ],
   "source": [
    "# grouped columns\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "x = np.arange(len(pos_order))\n",
    "barw = 0.8 / len(corpora_order)\n",
    "\n",
    "for i, cname in enumerate(corpora_order):\n",
    "    vals = df_pos_pct[cname].reindex(pos_order).values\n",
    "    ax.bar(x + i*barw - 0.4 + barw/2, vals, width=barw, label=cname)\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(pos_order, rotation=40, ha=\"right\")\n",
    "ax.set_ylabel(\"Anteil (%)\")\n",
    "ax.set_title(\"POS-Anteile nach Corpus (gruppiert)\")\n",
    "ax.legend()\n",
    "ax.grid(axis=\"y\", linestyle=\":\", linewidth=0.7, alpha=0.6)\n",
    "fig.tight_layout()\n",
    "fig.savefig(Path(OUTDIR) / \"POS_shares_grouped_bar.png\", dpi=200)\n",
    "fig.savefig(Path(OUTDIR) / \"POS_shares_grouped_bar.pdf\")\n",
    "plt.close(fig)\n",
    "\n",
    "# 100% grouped columns\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "bottom = np.zeros(len(corpora_order))\n",
    "for pos in pos_order:\n",
    "    vals = df_pos_pct.loc[pos, corpora_order].values\n",
    "    ax.bar(corpora_order, vals, bottom=bottom, label=pos)\n",
    "    bottom += vals\n",
    "\n",
    "ax.set_ylabel(\"Anteil (%)\")\n",
    "ax.set_title(\"POS-Anteil nach Corpus (100% gestapelt)\")\n",
    "ax.legend(ncol=2, fontsize=8, title=\"POS\")\n",
    "ax.grid(axis=\"y\", linestyle=\":\", linewidth=0.7, alpha=0.6)\n",
    "fig.tight_layout()\n",
    "fig.savefig(Path(OUTDIR) / \"POS_shares_stacked100.png\", dpi=200)\n",
    "fig.savefig(Path(OUTDIR) / \"POS_shares_stacked100.pdf\")\n",
    "plt.close(fig)\n",
    "\n",
    "# Heatmap\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "M = df_pos_pct[corpora_order].values  \n",
    "im = ax.imshow(M, aspect=\"auto\")  \n",
    "\n",
    "ax.set_yticks(np.arange(len(pos_order)))\n",
    "ax.set_yticklabels(pos_order)\n",
    "ax.set_xticks(np.arange(len(corpora_order)))\n",
    "ax.set_xticklabels(corpora_order, rotation=25, ha=\"right\")\n",
    "ax.set_title(\"POS-Share – Heatmap (%)\")\n",
    "\n",
    "\n",
    "for i in range(M.shape[0]):\n",
    "    for j in range(M.shape[1]):\n",
    "        val = M[i, j]\n",
    "        if val >= 1.0:\n",
    "            ax.text(j, i, f\"{val:.1f}\", ha=\"center\", va=\"center\", fontsize=7)\n",
    "\n",
    "fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04, label=\"Share (%)\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(Path(OUTDIR) / \"POS_shares_heatmap.png\", dpi=200)\n",
    "fig.savefig(Path(OUTDIR) / \"POS_shares_heatmap.pdf\")\n",
    "plt.close(fig)\n",
    "\n",
    "print(\"[OK] Visualisierungen gespeichert in:\", OUTDIR)\n",
    "print(\" - POS_shares_grouped_bar.(png|pdf)\")\n",
    "print(\" - POS_shares_stacked100.(png|pdf)\")\n",
    "print(\" - POS_shares_heatmap.(png|pdf)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ecb6ef-0522-4529-8db7-bcc5ed947461",
   "metadata": {},
   "source": [
    "Top 10 Adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b2a8be92-bb7e-4401-b431-fec2ed6cef60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Vorschau: Side-by-Side Top-10 ADJ (mit Counts) ===\n",
      "     Folk Fairy Tales  share_Folk Fairy Tales  count_Folk Fairy Tales    GPT-5  share_GPT-5  count_GPT-5   GPT-4o  share_GPT-4o  count_GPT-4o\n",
      "rank                                                                                                                                         \n",
      "1               gross                0.002275                     455      alt     0.002553          322      alt      0.003801           436\n",
      "2                 alt                0.001725                     345    klein     0.001974          249    klein      0.002058           236\n",
      "3               schön                0.001605                     321    gross     0.001427          180   golden      0.001221           140\n",
      "4             anderer                0.001450                     290   golden     0.001324          167  silbern      0.001151           132\n",
      "5               klein                0.001255                     251  schwarz     0.000904          114   dunkel      0.001037           119\n"
     ]
    }
   ],
   "source": [
    "def top_adj_table_side_by_side(n: int = TOP_N_ADJ) -> pd.DataFrame:\n",
    "    per_corpus_tops = {}\n",
    "    for cname, res in results.items():\n",
    "        tot = res[\"total_tokens\"] or 1\n",
    "        # (lemma, count, share)\n",
    "        triples = [(lem, cnt, cnt / tot) for lem, cnt in res[\"adj_counts\"].items()]\n",
    "        triples.sort(key=lambda x: x[2], reverse=True)  # nach Share\n",
    "        per_corpus_tops[cname] = triples[:n]\n",
    "\n",
    "    corpus_order = list(CORPORA.keys())\n",
    "    cols = []\n",
    "    for cname in corpus_order:\n",
    "        cols += [cname, f\"share_{cname}\", f\"count_{cname}\"]\n",
    "\n",
    "    data = []\n",
    "    for i in range(n):\n",
    "        row = {}\n",
    "        for cname in corpus_order:\n",
    "            if i < len(per_corpus_tops[cname]):\n",
    "                lem, cnt, sh = per_corpus_tops[cname][i]\n",
    "                row[cname] = lem\n",
    "                row[f\"share_{cname}\"] = round(sh, 6)\n",
    "                row[f\"count_{cname}\"] = int(cnt)\n",
    "            else:\n",
    "                row[cname] = \"\"\n",
    "                row[f\"share_{cname}\"] = np.nan\n",
    "                row[f\"count_{cname}\"] = np.nan\n",
    "        data.append(row)\n",
    "\n",
    "    df = pd.DataFrame(data, index=range(1, n + 1), columns=cols)\n",
    "    df.index.name = \"rank\"\n",
    "    return df\n",
    "\n",
    "df_adj_side = top_adj_table_side_by_side(TOP_N_ADJ)\n",
    "adj_side_csv = Path(OUTDIR) / f\"Top{TOP_N_ADJ}_ADJ_side_by_side.csv\"\n",
    "df_adj_side.to_csv(adj_side_csv, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"\\n=== Vorschau: Side-by-Side Top-{TOP_N_ADJ} ADJ (mit Counts) ===\")\n",
    "print(df_adj_side.head(5).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "97561cea-5efc-40d2-89c5-627e36ac94af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Vorschau: Side-by-Side Top-10 ADJ ===\n",
      "     Folk Fairy Tales  share_Folk Fairy Tales    GPT-5  share_GPT-5   GPT-4o  share_GPT-4o\n",
      "rank                                                                                      \n",
      "1               gross                0.002275      alt     0.002553      alt      0.003801\n",
      "2                 alt                0.001725    klein     0.001974    klein      0.002058\n",
      "3               schön                0.001605    gross     0.001427   golden      0.001221\n",
      "4             anderer                0.001450   golden     0.001324  silbern      0.001151\n",
      "5               klein                0.001255  schwarz     0.000904   dunkel      0.001037\n"
     ]
    }
   ],
   "source": [
    "def top_adj_table_side_by_side(n: int = TOP_N_ADJ) -> pd.DataFrame:\n",
    "    per_corpus_tops = {}\n",
    "    for cname, res in results.items():\n",
    "        tot = res[\"total_tokens\"] or 1\n",
    "        pairs = [(lem, cnt / tot) for lem, cnt in res[\"adj_counts\"].items()]\n",
    "        pairs.sort(key=lambda x: x[1], reverse=True)\n",
    "        per_corpus_tops[cname] = pairs[:n]\n",
    "    corpus_order = list(CORPORA.keys())\n",
    "    cols = []\n",
    "    for cname in corpus_order:\n",
    "        cols += [cname, f\"share_{cname}\"]\n",
    "\n",
    "    data = []\n",
    "    for i in range(n):\n",
    "        row = {}\n",
    "        for cname in corpus_order:\n",
    "            if i < len(per_corpus_tops[cname]):\n",
    "                lem, sh = per_corpus_tops[cname][i]\n",
    "                row[cname] = lem\n",
    "                row[f\"share_{cname}\"] = round(sh, 6)\n",
    "            else:\n",
    "                row[cname] = \"\"\n",
    "                row[f\"share_{cname}\"] = np.nan\n",
    "        data.append(row)\n",
    "\n",
    "    df = pd.DataFrame(data, index=range(1, n+1))\n",
    "    df.index.name = \"rank\"\n",
    "    return df\n",
    "\n",
    "df_adj_side = top_adj_table_side_by_side(TOP_N_ADJ)\n",
    "adj_side_csv = Path(OUTDIR) / f\"Top{TOP_N_ADJ}_ADJ_side_by_side.csv\"\n",
    "df_adj_side.to_csv(adj_side_csv, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"\\n=== Vorschau: Side-by-Side Top-{TOP_N_ADJ} ADJ ===\")\n",
    "print(df_adj_side.head(5).to_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
