{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2b8f6a9c-f386-4870-a93f-9239f14682c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, pathlib, typing\n",
    "from pathlib import Path\n",
    "from collections import Counter, defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from typing import List, Dict\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15df83e1-3eee-4c56-8507-17fe2d15b9a7",
   "metadata": {},
   "source": [
    "LOADING CORPORA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "04710583-75bb-461a-94ce-11afb2a24c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS_FFT   = r\"C:\\Users\\Sophia\\Downloads\\MA\\CORPORA\\German FFT\"\n",
    "CORPUS_LFT   = r\"C:\\Users\\Sophia\\Downloads\\MA\\CORPORA\\Literary Fairytales\"\n",
    "CORPUS_GPT_5 = r\"C:\\Users\\Sophia\\Downloads\\MA\\CORPORA\\GPT-5\"\n",
    "CORPUS_GPT_4 = r\"C:\\Users\\Sophia\\Downloads\\MA\\CORPORA\\GPT-4o\"\n",
    "\n",
    "CORPORA = {\n",
    "    \"Folk Fairy Tales\": CORPUS_FFT,\n",
    "    \"Literary Fairy Tales\": CORPUS_LFT,\n",
    "    \"GPT-5\": CORPUS_GPT_5,\n",
    "    \"GPT-4o\": CORPUS_GPT_4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "777e7398-a6ec-4711-ba5b-4fb6cee7971a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folk Fairy Tales: 123 Dateien\n",
      "Literary Fairy Tales: 13 Dateien\n",
      "GPT-5: 100 Dateien\n",
      "GPT-4o: 100 Dateien\n"
     ]
    }
   ],
   "source": [
    "for name, path in CORPORA.items():\n",
    "    files = list(Path(path).rglob(\"*.txt\"))\n",
    "    print(f\"{name}: {len(files)} Dateien\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29e96ca-2fc5-49ba-b2c3-fcdc8133333c",
   "metadata": {},
   "source": [
    "MOST FREQUENT WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e05c6230-c8a3-4a03-9f7f-7c4e23e6eb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD_RE = re.compile(r\"[A-Za-zÄÖÜäöüß]+\", flags=re.UNICODE)\n",
    "\n",
    "def read_text(p: Path) -> str:\n",
    "    return p.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "def tokens(text: str):\n",
    "    return [m.group(0).lower() for m in WORD_RE.finditer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2b5f21e2-7917-4470-b0b3-a88e30a8f185",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_MFW     = 1000\n",
    "CULLING_PCT = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2005c6b6-ae19-4b9f-833c-b23e05050e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Read: 336 docs from 4 Corpora.\n"
     ]
    }
   ],
   "source": [
    "#read docs\n",
    "docs_order = []\n",
    "groups = {}\n",
    "texts = {}\n",
    "\n",
    "for group_name, folder in CORPORA.items():\n",
    "    p = Path(folder)\n",
    "    for f in sorted(p.rglob(\"*.txt\")):\n",
    "        doc_id = f\"{group_name}__{f.name}\"\n",
    "        try:\n",
    "            txt = read_text(f)\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Couldn't read: {f} ({e})\")\n",
    "            continue\n",
    "        docs_order.append(doc_id)\n",
    "        groups[doc_id] = group_name\n",
    "        texts[doc_id] = txt\n",
    "\n",
    "print(f\"[INFO] Read: {len(docs_order)} docs from {len(set(groups.values()))} Corpora.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1ceace95-fb55-41b3-8ef9-e393d4a2b329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] After Culling 27590 words left; Chosen: Top 1000 MFW.\n",
      "[OK] Generated: MFW_freq_matrix_top1000_cull0.csv, MFW_terms_top1000_cull0.csv\n",
      "[OK] geschrieben: Top5_MFW_per_Corpus_top1000_cull0.csv\n",
      "\n",
      " Top-5 (Preview) \n",
      "group term  mean_rel_freq\n",
      "  FFT  und       0.054007\n",
      "  FFT  der       0.027702\n",
      "  FFT  die       0.026970\n",
      "  FFT  sie       0.020478\n",
      "  FFT   er       0.019475\n",
      " GPT4  und       0.041610\n",
      " GPT4  der       0.033581\n",
      " GPT4  sie       0.024131\n",
      " GPT4  die       0.023352\n",
      " GPT4  das       0.019049\n",
      " GPT5  und       0.049190\n",
      " GPT5  die       0.029715\n",
      " GPT5  sie       0.026765\n",
      " GPT5  der       0.026586\n",
      " GPT5   er       0.016876\n",
      "  LFT  und       0.036767\n",
      "  LFT  der       0.026749\n",
      "  LFT  die       0.025189\n",
      "  LFT   er       0.017495\n",
      "  LFT   in       0.016414\n",
      "\n",
      "[INFO] Docs / Corpus:\n",
      "FFT     123\n",
      "GPT5    100\n",
      "GPT4    100\n",
      "LFT      13\n"
     ]
    }
   ],
   "source": [
    "doc_token_counts = {}\n",
    "doc_lengths = {}\n",
    "df_counter = Counter()\n",
    "global_counts = Counter()\n",
    "\n",
    "for doc_id in docs_order:\n",
    "    toks = tokens(texts[doc_id])\n",
    "    cnt = Counter(toks)\n",
    "    doc_token_counts[doc_id] = cnt\n",
    "    L = sum(cnt.values())\n",
    "    doc_lengths[doc_id] = L\n",
    "    global_counts.update(cnt)\n",
    "    for w in cnt.keys():\n",
    "        df_counter[w] += 1\n",
    "\n",
    "n_docs = len(docs_order)\n",
    "cull_threshold = int(np.ceil(CULLING_PCT/100.0 * n_docs))\n",
    "vocab_culled = [w for w, df in df_counter.items() if df >= cull_threshold]\n",
    "vocab_sorted = sorted(vocab_culled, key=lambda w: global_counts[w], reverse=True)\n",
    "mfw = vocab_sorted[:TOP_MFW]\n",
    "print(f\"[INFO] After Culling {len(vocab_culled)} words left; Chosen: Top {len(mfw)} MFW.\")\n",
    "\n",
    "# Frequenzy Matrix\n",
    "rows = []\n",
    "for doc_id in docs_order:\n",
    "    total = max(doc_lengths[doc_id], 1)\n",
    "    row = {\"id\": doc_id, \"group\": groups[doc_id]}\n",
    "    cnt = doc_token_counts[doc_id]\n",
    "    for w in mfw:\n",
    "        row[w] = cnt.get(w, 0) / total\n",
    "    rows.append(row)\n",
    "\n",
    "df_freq = pd.DataFrame(rows).set_index(\"id\")\n",
    "df_freq.to_csv(\"MFW_freq_matrix_top1000_cull0.csv\", encoding=\"utf-8\")\n",
    "pd.Series(mfw, name=\"term\").to_csv(\"MFW_terms_top1000_cull0.csv\", index=False, encoding=\"utf-8\")\n",
    "print(\"[OK] Generated: MFW_freq_matrix_top1000_cull0.csv, MFW_terms_top1000_cull0.csv\")\n",
    "\n",
    "# Top-5 MFW \n",
    "mfw_cols = [c for c in df_freq.columns if c != \"group\"]\n",
    "group_means = df_freq.groupby(\"group\")[mfw_cols].mean()\n",
    "\n",
    "top5_rows = []\n",
    "for grp in group_means.index:\n",
    "    sub = group_means.loc[grp].sort_values(ascending=False).head(5)\n",
    "    for term, val in sub.items():\n",
    "        top5_rows.append({\"group\": grp, \"term\": term, \"mean_rel_freq\": val})\n",
    "\n",
    "df_top5 = pd.DataFrame(top5_rows).sort_values([\"group\",\"mean_rel_freq\"], ascending=[True, False])\n",
    "df_top5.to_csv(\"Top5_MFW_per_Corpus_top1000_cull0.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"[OK] geschrieben: Top5_MFW_per_Corpus_top1000_cull0.csv\")\n",
    "print(\"\\n Top-5 (Preview) \")\n",
    "print(df_top5.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b15df9a5-955d-4729-9847-efd3c4b2f76f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\Top 5\n",
      "     FFT_term FFT_mean_rel_freq LFT_term LFT_mean_rel_freq GPT4_term  \\\n",
      "Rank                                                                   \n",
      "1         und            0.0540      und            0.0368       und   \n",
      "2         der            0.0277      der            0.0267       der   \n",
      "3         die            0.0270      die            0.0252       sie   \n",
      "4         sie            0.0205       er            0.0175       die   \n",
      "5          er            0.0195       in            0.0164       das   \n",
      "\n",
      "     GPT4_mean_rel_freq GPT5_term GPT5_mean_rel_freq  \n",
      "Rank                                                  \n",
      "1                0.0416       und             0.0492  \n",
      "2                0.0336       die             0.0297  \n",
      "3                0.0241       sie             0.0268  \n",
      "4                0.0234       der             0.0266  \n",
      "5                0.0190        er             0.0169  \n"
     ]
    }
   ],
   "source": [
    "df_top5 = pd.read_csv(\"Top5_MFW_per_Corpus_top1000_cull0.csv\")\n",
    "order = [\"FFT\", \"LFT\", \"GPT4\", \"GPT5\"]\n",
    "blocks = []\n",
    "for grp in order:\n",
    "    sub = df_top5[df_top5[\"group\"] == grp].copy()\n",
    "    sub = sub.sort_values(\"mean_rel_freq\", ascending=False).head(5).reset_index(drop=True)\n",
    "    sub.index = pd.Index(range(1, len(sub)+1), name=\"Rank\")\n",
    "    sub.columns = [ \"group\", f\"{grp}_term\", f\"{grp}_mean_rel_freq\" ]\n",
    "    sub = sub.drop(columns=[\"group\"])\n",
    "    blocks.append(sub)\n",
    "\n",
    "side_by_side = pd.concat(blocks, axis=1)\n",
    "fmt = side_by_side.copy()\n",
    "for grp in order:\n",
    "    col = f\"{grp}_mean_rel_freq\"\n",
    "    if col in fmt.columns:\n",
    "        fmt[col] = fmt[col].map(lambda x: f\"{x:.4f}\")\n",
    "\n",
    "print(\"\\Top 5\")\n",
    "print(fmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2c5dc1e5-92ff-450c-a00f-2a1e2a0190c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[OK] Generated: Top5_MFW.csv\n"
     ]
    }
   ],
   "source": [
    "side_by_side.to_csv(\"Top5_MFW.csv\", encoding=\"utf-8\")\n",
    "print(\"\\n[OK] Generated: Top5_MFW.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
